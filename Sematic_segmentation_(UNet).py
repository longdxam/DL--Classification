# -*- coding: utf-8 -*-
"""chuan_bi_du_lieu.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19FeMmidqf-3RkxM2lV39EYG-Vt3Y0YXg
"""

!pip install -U torchmetrics          # tính toán độ chính xác
!pip install segmentation-models-pytorch
!pip install albumentations        # tạo ra nhiều dạng ảnh (data augmentation)

!wget https://thor.robots.ox.ac.uk/~vgg/data/pets/images.tar.gz
!wget https://thor.robots.ox.ac.uk/~vgg/data/pets/annotations.tar.gz

!tar -xf annotations.tar.gz
!tar -xf images.tar.gz

import numpy as np
import cv2
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torchmetrics
from torchmetrics.classification import MulticlassF1Score, MulticlassJaccardIndex

import segmentation_models_pytorch as smp
import albumentations as A
from albumentations.pytorch import ToTensorV2  # np.arrays -> torch.tensor
import os
from tqdm import tqdm  # tạo ra thanh progress bar
from glob import glob  # hỗ trợ đọc file ảnh

# Metric: Dice = F1, IoU = Jaccard
dice_metric = MulticlassF1Score(num_classes=3, average="macro")
iou_metric = MulticlassJaccardIndex(num_classes=3, average="macro")

# ĐỌC 1 MASK (NHÃN)
mask_path = "/content/annotations/trimaps/Abyssinian_1.png"
mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) #anh kết quả 0,1 nên chỉ cần đọc ở dạng ảnh xám
print(np.unique(mask)) # đưa ra các pixxel khác nhau trong ảnh
plt.imshow(mask)

#ĐỌC 1 ẢNH
image_path = "/content/images/Abyssinian_10.jpg"
image = cv2.imread(image_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #chuyển sang RGB để cv2 đọc ảnh, ảnh bình thường ở dạng BGR
plt.imshow(image)

class DogCatDataset(Dataset):
  def __init__(self, root_dir, txt_file, transform = None): #tranform: augmenttation + norm(chuyen thanh 0->1) + np.array->torch.tensor
      super().__init__()
      self.root_dir = root_dir
      self.txt_file = txt_file
      self.transform = transform
      self.img_path_lst = []
      with open(self.txt_file) as file_in:
          for line in file_in:
            self.img_path_lst.append(line.split(" ")[0])


  def __len__(self):
      return len(self.img_path_lst)


  def __getitem__(self,idx):
      image_path = os.path.join(self.root_dir, "images", "{}.jpg".format(self.img_path_lst[idx]))
      mask_path = os.path.join(self.root_dir, "annotations", "trimaps", "{}.png".format(self.img_path_lst[idx]))
      image = cv2.imread(image_path)
      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
      mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
      #foreground : 1
      #background : 2 -> 0
      #đường viền : 3 -> 1
      mask[mask == 2] = 0
      mask[mask == 3] = 1
      #image (RGB), mask(2D matrix)
      if self.transform is not None:
          transformed = self.transform(image = image, mask = mask)
          transformed_image = transformed["image"]
          transformed_mask = transformed["mask"]


      return transformed_image, transformed_mask

trainsize = 384
train_transform = A.Compose([
    A.Resize(width = trainsize, height = trainsize),
    A.HorizontalFlip(),
    A.RandomBrightnessContrast(),
    A.Blur(),
    A.RGBShift(),
    A.CoarseDropout(max_holes=5, max_height=25, max_width=25, fill_value=0, mask_fill_value=0),

    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
    ToTensorV2()
])

test_transform = A.Compose([
    A.Resize(width = trainsize, height = trainsize),
    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
    ToTensorV2()
])



train_dataset = DogCatDataset("/content", "/content/annotations/trainval.txt",train_transform)
test_dataset = DogCatDataset("/content", "/content/annotations/test.txt", test_transform)
image, mask = trai  n_dataset.__getitem__(10)
print(image.shape, mask.shape)
print(np.unique(mask))

import matplotlib.pyplot as plt

# Lấy 1 sample từ dataset
image, mask = train_dataset[10]   # image: torch.tensor (C,H,W), mask: torch.tensor (H,W)

# Chuyển image từ (C,H,W) -> (H,W,C) và về numpy để hiển thị
image_np = image.permute(1, 2, 0).cpu().numpy()
mask_np = mask.cpu().numpy()

# Vì image đã Normalize nên cần đảo ngược normalize để nhìn cho đẹp
mean = [0.485, 0.456, 0.406]
std  = [0.229, 0.224, 0.225]
image_np = std * image_np + mean
image_np = (image_np * 255).astype("uint8")

# Vẽ
plt.figure(figsize=(10,5))

plt.subplot(1,2,1)
plt.imshow(image_np)
plt.title("Image")
plt.axis("off")

plt.subplot(1,2,2)
plt.imshow(mask_np, cmap="gray")
plt.title("Mask")
plt.axis("off")

plt.show()

#MODEL UNet
def unet_block(in_channels, out_channels):
    return nn.Sequential(
        nn.Conv2d(in_channels, out_channels, 3,1,1),
        nn.ReLU(),
        nn.Conv2d(out_channels, out_channels, 3, 1, 1),
        nn.ReLU()

    )

class Unet(nn.Module):
    def __init__(self, n_classes):
        super().__init__()
        self.n_classes = n_classes
        self.downsample = nn.MaxPool2d(2) #giam kích cỡ ảnh mỗi lần down
        self.upsample = nn.Upsample(scale_factor=2, mode="bilinear") #noi suy
        self.block_down1 = unet_block(3,64)
        self.block_down2 = unet_block(64, 128)
        self.block_down3 = unet_block(128, 256)
        self.block_down4 = unet_block(256, 512)
        self.block_next = unet_block(512, 1024)
        self.block_up1 = unet_block(1024 + 512, 512)
        self.block_up2 = unet_block(512 + 256, 256)
        self.block_up3 = unet_block(256 + 128, 128)
        self.block_up4 = unet_block(128 + 64, 64)

        self.conv_cls = nn.Conv2d(64, n_classes, 1) #1 la kenersize

    def forward(self,x):
        x1 = self.block_down1(x)
        x = self.downsample(x1)
        x2 = self.block_down2(x)
        x = self.downsample(x2)
        x3 = self.block_down3(x)
        x = self.downsample(x3)
        x4 = self.block_down4(x)
        x = self.downsample(x4)

        x = self.block_next(x)

        #(B, 1024, H, W) cat (B, 512, H , W) - > (B, 1536, H, W)
        x = torch.cat([x4, self.upsample(x)], 1)
        x = self.block_up1(x)
        x = torch.cat([x3, self.upsample(x)], 1)
        x = self.block_up2(x)
        x = torch.cat([x2, self.upsample(x)], 1)
        x = self.block_up3(x)
        x = torch.cat([x1, self.upsample(x)], 1)
        x = self.block_up4(x)

        x = self.conv_cls(x)
        return x

# model =Unet(1)
# x = torch.rand(4,3,trainsize, trainsize)
# print(x.shape)
# y = model(x)
# print(y.shape)
# y true : (4, 384, 384)
# y du doan (4,1,384,384)

class AverageMeter(object):
    """Computes and stores the average and current value"""
    def __init__(self):
        self.reset()

    def reset(self):
        """Reset all states"""
        self.val = 0       # giá trị hiện tại
        self.avg = 0       # giá trị trung bình
        self.sum = 0       # tổng cộng
        self.count = 0     # số lượng

    def update(self, val, n=1):
        """Cập nhật thêm giá trị mới"""
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count

def accuracy_function(predicts, targets):
  pred_flat = predicts.flatten()
  target_flat = targets.flatten()
  accuracy = torch.sum(pred_flat == target_flat)
  return accuracy/target_flat.shape[0]

#device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


#load data
batch_size = 8
train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False, num_workers=2)

#model
model = Unet(1).to(device)


#loss
criterion = nn.BCEWithLogitsLoss()

#optimizer
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
n_eps = 30

#metrics
from torchmetrics.segmentation import DiceScore
from torchmetrics.classification import JaccardIndex

dice_fn = DiceScore(num_classes=2, average="macro", include_background=False).to(device)
iou_fn = JaccardIndex(task="binary", num_classes=2, average="macro").to(device)

#meter
acc_meter = AverageMeter()
train_loss_meter = AverageMeter()
dice_meter = AverageMeter()
iou_meter = AverageMeter()

# train loop
for ep in range(1, 1 + n_eps):
    acc_meter.reset()
    train_loss_meter.reset()
    dice_meter.reset()
    iou_meter.reset()

    for batch_id, (x, y) in enumerate(tqdm(train_loader), start=1):
        optimizer.zero_grad()  # reset gradient
        n = x.shape[0]

        # đưa dữ liệu lên GPU
        x = x.to(device).float()
        y = y.to(device)

        # chuẩn hóa nhãn
        if y.ndim == 3:   # (B,H,W)
            y = y.unsqueeze(1)   # (B,1,H,W)
        y = y.float()
        y = (y > 0).float()      # đảm bảo nhãn {0,1}

        # forward
        y_hat = model(x)                 # logit (-∞ → +∞), shape (B,1,H,W)
        loss = criterion(y_hat, y)

        # backward
        loss.backward()
        optimizer.step()

        # metrics
        with torch.no_grad():
            y_hat_mask = torch.sigmoid(y_hat).round().long()  # (B,1,H,W)

            # squeeze channel để metric nhận dạng đúng (B,H,W)
            y_hat_mask = y_hat_mask.squeeze(1)
            y_true = y.squeeze(1).long()

            dice_score = dice_fn(y_hat_mask, y_true)
            iou_score = iou_fn(y_hat_mask, y_true)
            accuracy = accuracy_function(y_hat_mask, y_true)

            train_loss_meter.update(loss.item(), n)
            dice_meter.update(dice_score.item(), n)
            iou_meter.update(iou_score.item(), n)
            acc_meter.update(accuracy.item(), n)

    # log kết quả
    print(
        f"EP {ep}, train loss = {train_loss_meter.avg:.4f}, "
        f"acc = {acc_meter.avg:.4f}, IoU = {iou_meter.avg:.4f}, "
        f"dice = {dice_meter.avg:.4f}"
    )

    # lưu model sau ep 25
    if ep >= 25:
        torch.save(model.state_dict(), f"/content/model_ep{ep}.pth")