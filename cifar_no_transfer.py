# -*- coding: utf-8 -*-
"""cifar-no_transfer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ucWl6psc14ilpk1-yWeE2Zeb0PwgveCT
"""

import numpy as np
import cv2
import matplotlib.pyplot as plt

import torchvision.datasets as datasets
import torchvision.transforms as transforms

train_dataset = datasets.CIFAR10(
    root = './data',
    train = True,
    download=True,
    transform = transforms.ToTensor()
)

test_dataset = datasets.CIFAR10(
    root = './data',
    train = False,
    download = True,
    transform=transforms.ToTensor()
)

print(len(train_dataset))
print(len(test_dataset))
image, lable = train_dataset[0]

image.shape
# img = image.numpy()
# img = np.transpose(img, (1,2,0)) #cu l√† 0, 1, 2

# plt.imshow(img)

import torch
import torch.nn as nn
from torch.utils.data import DataLoader

class CNN(nn.Module):
  def __init__(self, num_class = 10):
    super().__init__()
    self.conv1 = self.make_block(in_channels=3, out_channels=8)
    self.conv2 = self.make_block(in_channels =8, out_channels=16)
    self.conv3 = self.make_block(in_channels=16, out_channels=32)
    self.conv4 = self.make_block(in_channels=32, out_channels=64)
    self.conv5 = self.make_block(in_channels=64, out_channels=128)
    self.flatten = nn.Flatten()

    self.fc1 = nn.Sequential(
        nn.Dropout(p=0.5),
        nn.Linear(in_features = 128, out_features = 512),
        nn.ReLU()
    )

    self.fc2 = nn.Sequential(
        nn.Dropout(p=0.5),
        nn.Linear(in_features=512, out_features = 1024),
        nn.ReLU()
    )

    self.fc3 = nn.Sequential(
        nn.Dropout(p=0.5),
        nn.Linear(in_features=1024, out_features = num_class),

    )


  def make_block(self, in_channels, out_channels):
    return nn.Sequential(
        nn.Conv2d(in_channels = in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding='same'),
        nn.BatchNorm2d(num_features=out_channels),
        nn.ReLU(),
        nn.Conv2d(in_channels=out_channels, out_channels=out_channels,kernel_size=3,stride = 1,padding='same'),
        nn.BatchNorm2d(num_features=out_channels),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2)
    )

  def forward(self, x):
      x = self.conv1(x)
      x = self.conv2(x)
      x = self.conv3(x)
      x = self.conv4(x)
      x = self.conv5(x)
      x = x.flatten(1)
      x = self.fc1(x)
      x = self.fc2(x)
      x = self.fc3(x)
      return x

train_dataloader = DataLoader(
    dataset = train_dataset,
    batch_size = 16,
    num_workers = 2,
    shuffle = True,
    drop_last=True
)

test_dataloader = DataLoader(
    dataset = test_dataset,
    batch_size = 16,
    num_workers = 2,
    shuffle = True,
    drop_last = True
)

model = CNN()
input_data = torch.randn(16,3,32,32)
output = model(input_data)
output.shape

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

num_epochs = 20
num_iters = len(train_dataloader)

for epoch in range(num_epochs):
  model.train()
  for i, (image, label) in enumerate(train_dataloader):
      #forward
      outputs = model(image)
      loss_value = criterion(outputs, label)
      print("Epoch {}/{}. Interation {}/{}. Loss {}".format(epoch + 1, num_epochs, i+1,num_iters, loss_value))

      #backward
      optimizer.zero_grad()
      loss_value.backward()
      optimizer.step()

  model.eval()
  correct = 0
  total = 0

  with torch.no_grad():
    for image, label in test_dataloader:
      outputs = model(image)
      _, predicted = torch.max(outputs, 1)
      total += label.size(0)
      correct += (predicted == label).sum().item()
  acc = 100 * correct / total
  print("Epoch {}/{}. Accuracy on test set : {:2f}%".format(epoch+1, num_epochs, acc))